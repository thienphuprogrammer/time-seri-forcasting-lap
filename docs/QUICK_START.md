# Quick Start Guide - DAT301m Lab 4

## Giá»›i thiá»‡u

Package nÃ y cung cáº¥p giáº£i phÃ¡p hoÃ n chá»‰nh cho **DAT301m Lab 4: Time Series Forecasting** vá»›i dá»¯ liá»‡u PJM hourly energy consumption.

## CÃ i Ä‘áº·t nhanh

```bash
# Clone repository
git clone <repository-url>
cd Time-Series-Forecasting

# CÃ i Ä‘áº·t dependencies
pip install -r requirements.txt

# Hoáº·c sá»­ dá»¥ng uv
uv sync
```

## Sá»­ dá»¥ng nhanh

### Option 1: Jupyter Notebooks (Khuyáº¿n nghá»‹ cho Lab)

```bash
# Cháº¡y tá»«ng task riÃªng biá»‡t
jupyter notebook notebooks/task1.ipynb  # Data Exploration (1.5 Ä‘iá»ƒm)
jupyter notebook notebooks/task2.ipynb  # Baseline Models (3 Ä‘iá»ƒm)
jupyter notebook notebooks/task3.ipynb  # Deep Learning (4 Ä‘iá»ƒm)
jupyter notebook notebooks/task4.ipynb  # Transformers (1.5 Ä‘iá»ƒm)

# Hoáº·c xem summary tá»•ng quan
jupyter notebook notebooks/lab4_complete_summary.ipynb
```

### Option 2: Demo hoÃ n chá»‰nh

```bash
python examples/lab4_complete_demo.py
```

### Option 3: Complete Analysis Notebook

```bash
jupyter notebook notebooks/01_complete_analysis.ipynb
```

### Option 4: Programmatic Usage

```python
from time_series_forecasting.analysis.lab_interface.lab4_interface import Lab4Interface

# Khá»Ÿi táº¡o
lab = Lab4Interface()

# Load data
data = lab.load_data('data/PJME_hourly.csv', region='PJME')

# Thá»±c hiá»‡n cÃ¡c tasks
task1_results = lab.execute_task1()
task2_results = lab.execute_task2(model_configs=baseline_models)
task3_results = lab.execute_task3(model_configs=deep_learning_models)
task4_results = lab.execute_task4(model_configs=transformer_models)

# LÆ°u káº¿t quáº£
lab.save_results('output_dir')
```

## Cáº¥u trÃºc Notebooks

### ðŸ“š Individual Task Notebooks:
1. **task1.ipynb** - Data Exploration & Preprocessing
   - Load vÃ  preprocess dá»¯ liá»‡u PJME
   - Comprehensive data analysis vÃ  visualization
   - WindowGenerator implementation
   - Train/validation/test splits

2. **task2.ipynb** - Baseline Models
   - Linear Regression vÃ  ARIMA models
   - Early stopping vÃ  evaluation
   - Model comparison vÃ  Q1 answer
   - Performance visualization

3. **task3.ipynb** - Deep Learning Models
   - RNN, GRU, LSTM implementations
   - Training vá»›i early stopping
   - Architecture comparison vÃ  Q2 answer
   - Deep learning evaluation

4. **task4.ipynb** - Transformer Models
   - Multi-Head Attention Transformer
   - Positional encoding vÃ  layer normalization
   - Comparison vá»›i Task 3 models
   - Advanced architecture analysis

5. **lab4_complete_summary.ipynb** - Complete Overview
   - Tá»•ng káº¿t táº¥t cáº£ tasks
   - Score breakdown: 10/10 Ä‘iá»ƒm
   - Usage instructions vÃ  expected results

## Cáº¥u trÃºc outputs

Sau khi cháº¡y, káº¿t quáº£ sáº½ Ä‘Æ°á»£c lÆ°u vÃ o thÆ° má»¥c Ä‘Æ°á»£c chá»‰ Ä‘á»‹nh:

```
lab4_results/
â”œâ”€â”€ plots/
â”‚   â”œâ”€â”€ time_series.png
â”‚   â”œâ”€â”€ seasonal_patterns.png
â”‚   â”œâ”€â”€ distribution.png
â”‚   â”œâ”€â”€ trends.png
â”‚   â”œâ”€â”€ anomalies.png
â”‚   â””â”€â”€ correlation.png
â”œâ”€â”€ analysis_results.json
â””â”€â”€ task_results.json
```

## Tasks Ä‘Æ°á»£c hoÃ n thÃ nh

### âœ… Task 1: Data Exploration (1.5 Ä‘iá»ƒm)
- Load vÃ  preprocess dá»¯ liá»‡u PJM
- Parse datetime, normalize data
- Táº¡o visualizations: time series, seasonal patterns, distributions
- Implement WindowGenerator class
- Chia train/validation/test

### âœ… Task 2: Baseline Models (3 Ä‘iá»ƒm)
- Linear Regression vá»›i lagged features (1 Ä‘iá»ƒm)
- ARIMA models vá»›i parameter tuning (1 Ä‘iá»ƒm)
- Early stopping vÃ  evaluation (0.5 Ä‘iá»ƒm)
- Training/validation curves vÃ  Q1 answer (0.5 Ä‘iá»ƒm)

### âœ… Task 3: Deep Learning Models (4 Ä‘iá»ƒm)
- RNN, GRU, LSTM models (3 Ä‘iá»ƒm)
- Early stopping vÃ  comprehensive evaluation
- Model comparison vÃ  visualization (0.5 Ä‘iá»ƒm)
- Q2 answer: Temporal pattern analysis (0.5 Ä‘iá»ƒm)

### âœ… Task 4: Transformer Models (1.5 Ä‘iá»ƒm)
- Transformer vá»›i multi-head attention (1 Ä‘iá»ƒm)
- Positional encoding vÃ  layer normalization
- So sÃ¡nh vá»›i Task 3 models (0.5 Ä‘iá»ƒm)

## Lab Questions

### Q1: MÃ´ hÃ¬nh nÃ o khÃ¡i quÃ¡t tá»‘t hÆ¡n vÃ  táº¡i sao?
- Notebooks sáº½ tá»± Ä‘á»™ng so sÃ¡nh cÃ¡c mÃ´ hÃ¬nh dá»±a trÃªn MAE vÃ  RMSE
- Linear Regression cÃ³ Ä‘á»™ phá»©c táº¡p tháº¥p, Ã­t overfitting
- ARIMA phÃ¹ há»£p vá»›i dá»¯ liá»‡u seasonal
- Analysis Ä‘Æ°á»£c include trong task2.ipynb

### Q2: MÃ´ hÃ¬nh nÃ o náº¯m báº¯t máº«u thá»i gian tá»‘t nháº¥t?
- LSTM thÆ°á»ng tá»‘t cho long-term dependencies
- GRU Ä‘Æ¡n giáº£n hÆ¡n LSTM vá»›i hiá»‡u suáº¥t tÆ°Æ¡ng tá»±
- Transformer cÃ³ thá»ƒ tá»‘t hÆ¡n vá»›i attention mechanism
- RNN cÃ³ thá»ƒ bá»‹ vanishing gradient
- Detailed analysis trong task3.ipynb

## Datasets há»— trá»£

Package há»— trá»£ táº¥t cáº£ regions cá»§a PJM:
- `PJME_hourly.csv` - PJM East (khuyáº¿n nghá»‹ cho notebooks)
- `PJMW_hourly.csv` - PJM West
- `AEP_hourly.csv` - American Electric Power
- `COMED_hourly.csv` - Commonwealth Edison
- VÃ  nhiá»u regions khÃ¡c...

## Troubleshooting

### Lá»—i import
```bash
# Äáº£m báº£o Ä‘ang á»Ÿ thÆ° má»¥c root
cd Time-Series-Forecasting

# CÃ i Ä‘áº·t package
pip install -e .
```

### Lá»—i memory khi train models
```python
# Giáº£m epochs hoáº·c batch size trong notebooks
train_params = {'epochs': 20, 'batch_size': 16}
```

### Lá»—i data khÃ´ng tÃ¬m tháº¥y
```bash
# Äáº£m báº£o data file tá»“n táº¡i
ls data/PJME_hourly.csv
```

### Jupyter notebook issues
```bash
# Install jupyter if needed
pip install jupyter

# Run tá»« project root
cd Time-Series-Forecasting
jupyter notebook
```

## Recommended Workflow

1. **Start with Summary**: `lab4_complete_summary.ipynb` Ä‘á»ƒ hiá»ƒu tá»•ng quan
2. **Run Individual Tasks**: 
   - `task1.ipynb` â†’ `task2.ipynb` â†’ `task3.ipynb` â†’ `task4.ipynb`
3. **Alternative**: Run `lab4_complete_demo.py` cho automated workflow
4. **Explore**: `01_complete_analysis.ipynb` cho detailed analysis

## Support

Náº¿u gáº·p lá»—i, kiá»ƒm tra:
1. Python version >= 3.8
2. Dependencies Ä‘Æ°á»£c cÃ i Ä‘áº·t Ä‘Ãºng
3. Data files tá»“n táº¡i trong thÆ° má»¥c `data/`
4. CÃ³ Ä‘á»§ disk space cho outputs
5. Jupyter notebook running tá»« project root

---

**Good luck vá»›i Lab 4! ðŸš€**

**ðŸ“Š Expected Score: 10/10 Ä‘iá»ƒm** 