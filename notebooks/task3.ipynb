{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Task 3: Deep Learning Models (4 ƒëi·ªÉm)\n",
        "\n",
        "## M·ª•c ti√™u\n",
        "- X√¢y d·ª±ng c√°c m√¥ h√¨nh h·ªçc s√¢u: RNN, GRU, LSTM ho·∫∑c hybrid (k·∫øt h·ª£p CNN)\n",
        "- M√¥ h√¨nh ensemble: k·∫øt h·ª£p nhi·ªÅu m√¥ h√¨nh s√¢u ho·∫∑c k·∫øt h·ª£p v·ªõi Random Forest/XGBoost\n",
        "- Hu·∫•n luy·ªán c√≥ early stopping, ƒë√°nh gi√° b·∫±ng MAE, RMSE\n",
        "- V·∫Ω bi·ªÉu ƒë·ªì loss/accuracy v√† bi·ªÉu ƒë·ªì d·ª± b√°o\n",
        "- **N√¢ng cao**: Multi-step forecasting (24 gi·ªù ho·∫∑c 7 ng√†y)\n",
        "\n",
        "## Y√™u c·∫ßu ho√†n th√†nh\n",
        "‚úÖ RNN/LSTM/CNN models (3 ƒëi·ªÉm)  \n",
        "‚úÖ Training v·ªõi early stopping v√† evaluation  \n",
        "‚úÖ Visualization v√† comparison plots (0.5 ƒëi·ªÉm)  \n",
        "‚úÖ Q2 answer analysis (0.5 ƒëi·ªÉm)  \n",
        "üöÄ **Bonus**: Multi-step forecasting (1 ƒëi·ªÉm)\n",
        "\n",
        "### C√¢u h·ªèi Q2: \n",
        "**M√¥ h√¨nh n√†o n·∫Øm b·∫Øt m·∫´u th·ªùi gian t·ªët nh·∫•t? ∆Øu nh∆∞·ª£c ƒëi·ªÉm c·ªßa t·ª´ng ki·∫øn tr√∫c?**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-22 22:35:29.914499: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-07-22 22:35:29.921945: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1753198529.930979   60951 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1753198529.933751   60951 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1753198529.940361   60951 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1753198529.940369   60951 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1753198529.940370   60951 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1753198529.940371   60951 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-07-22 22:35:29.942984: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Libraries imported for Task 3: Deep Learning Models\n",
            "üß† Ready for neural networks training!\n",
            "\n",
            "üìã Configuration: PJME data, 24h‚Üí1h forecast\n"
          ]
        }
      ],
      "source": [
        "# Import libraries cho Task 3\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import our modules\n",
        "import sys\n",
        "import os\n",
        "sys.path.append(os.path.dirname(os.getcwd()))\n",
        "\n",
        "from time_series_forecasting.analysis.lab_interface.lab4_interface import Lab4Interface\n",
        "\n",
        "print(\"‚úÖ Libraries imported for Task 3: Deep Learning Models\")\n",
        "print(\"üß† Ready for neural networks training!\")\n",
        "\n",
        "# Configuration from previous tasks\n",
        "config = {\n",
        "    'data_path': '../data/PJME_hourly.csv',\n",
        "    'region': 'PJME', \n",
        "    'target_col': 'PJME_MW',\n",
        "    'datetime_col': 'Datetime',\n",
        "    'input_width': 24,\n",
        "    'label_width': 1,\n",
        "    'shift': 1\n",
        "}\n",
        "\n",
        "print(f\"\\nüìã Configuration: {config['region']} data, {config['input_width']}h‚Üí{config['label_width']}h forecast\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3.1 Deep Learning Models Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Auto-detected PJM format:\n",
            "  Datetime -> 'Datetime'\n",
            "  PJME_MW -> 'MW'\n",
            "Loaded data shape: (145366, 2)\n",
            "Columns: ['Datetime', 'MW']\n",
            "Parsed datetime. Date range: 2002-01-01 01:00:00 to 2018-08-03 00:00:00\n",
            "Missing values before handling: 0\n",
            "Missing values after handling: 0\n",
            "Removed 4 duplicate rows\n",
            "Missing values before handling: 1318\n",
            "Missing values after handling: 0\n",
            "Removed 1318 outliers using zscore method\n",
            "Transformed 1 columns using minmax scaling\n",
            "‚úÖ Data loaded - Shape: (145362, 1)\n",
            "üß† Deep Learning Models Configuration:\n",
            "----------------------------------------\n",
            "1. Simple_RNN (RNN)\n",
            "   Units: 64, Layers: 2\n",
            "   Dropout: 0.2, LR: 0.001\n",
            "2. GRU (GRU)\n",
            "   Units: 64, Layers: 2\n",
            "   Dropout: 0.2, LR: 0.001\n",
            "3. LSTM (LSTM)\n",
            "   Units: 64, Layers: 2\n",
            "   Dropout: 0.2, LR: 0.001\n",
            "\n",
            "üìê Window config: {'input_width': 24, 'label_width': 1, 'shift': 1}\n",
            "üéØ Total models to train: 3\n"
          ]
        }
      ],
      "source": [
        "# Initialize Lab4Interface v√† load data\n",
        "lab = Lab4Interface()\n",
        "data = lab.load_data(config['data_path'], region=config['region'])\n",
        "\n",
        "print(f\"‚úÖ Data loaded - Shape: {data.shape}\")\n",
        "\n",
        "# Define deep learning model configurations\n",
        "deep_learning_models = [\n",
        "    {\n",
        "        'type': 'rnn',\n",
        "        'name': 'Simple_RNN',\n",
        "        'config': {\n",
        "            'units': 64,\n",
        "            'layers': 2,\n",
        "            'dropout': 0.2,\n",
        "            'learning_rate': 0.001\n",
        "        },\n",
        "        'train_params': {'epochs': 50, 'patience': 10, 'verbose': 1},\n",
        "        'metrics': ['mae', 'rmse']\n",
        "    },\n",
        "    {\n",
        "        'type': 'gru',\n",
        "        'name': 'GRU',\n",
        "        'config': {\n",
        "            'units': 64,\n",
        "            'layers': 2,\n",
        "            'dropout': 0.2,\n",
        "            'learning_rate': 0.001\n",
        "        },\n",
        "        'train_params': {'epochs': 50, 'patience': 10, 'verbose': 1},\n",
        "        'metrics': ['mae', 'rmse']\n",
        "    },\n",
        "    {\n",
        "        'type': 'lstm',\n",
        "        'name': 'LSTM',\n",
        "        'config': {\n",
        "            'units': 64,\n",
        "            'layers': 2,\n",
        "            'dropout': 0.2,\n",
        "            'learning_rate': 0.001\n",
        "        },\n",
        "        'train_params': {'epochs': 50, 'patience': 10, 'verbose': 1},\n",
        "        'metrics': ['mae', 'rmse']\n",
        "    }\n",
        "]\n",
        "\n",
        "print(\"üß† Deep Learning Models Configuration:\")\n",
        "print(\"-\" * 40)\n",
        "for i, model in enumerate(deep_learning_models, 1):\n",
        "    print(f\"{i}. {model['name']} ({model['type'].upper()})\")\n",
        "    print(f\"   Units: {model['config']['units']}, Layers: {model['config']['layers']}\")\n",
        "    print(f\"   Dropout: {model['config']['dropout']}, LR: {model['config']['learning_rate']}\")\n",
        "\n",
        "# Window configuration\n",
        "window_config = {\n",
        "    'input_width': config['input_width'],\n",
        "    'label_width': config['label_width'],\n",
        "    'shift': config['shift']\n",
        "}\n",
        "\n",
        "print(f\"\\nüìê Window config: {window_config}\")\n",
        "print(f\"üéØ Total models to train: {len(deep_learning_models)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3.2 Training Deep Learning Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Training Deep Learning Models...\n",
            "============================================================\n",
            "‚è∞ This may take several minutes depending on your hardware...\n",
            "üí° Models will use early stopping to prevent overfitting\n",
            "\n",
            "Data splits - Train: 101753, Val: 21804, Test: 21805\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-22 22:35:30.891166: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m3180/3180\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0118 - mae: 0.0665\n",
            "Epoch 2/50\n",
            "\u001b[1m3180/3180\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0069 - mae: 0.0462\n",
            "Epoch 3/50\n",
            "\u001b[1m3180/3180\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0065 - mae: 0.0423\n",
            "Epoch 4/50\n",
            "\u001b[1m3180/3180\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 0.0065 - mae: 0.0408\n",
            "Epoch 5/50\n",
            "\u001b[1m3180/3180\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0064 - mae: 0.0399\n",
            "Epoch 6/50\n",
            "\u001b[1m3180/3180\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0063 - mae: 0.0393\n",
            "Epoch 7/50\n",
            "\u001b[1m3180/3180\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0063 - mae: 0.0385\n",
            "Epoch 8/50\n",
            "\u001b[1m3180/3180\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0061 - mae: 0.0374\n",
            "Epoch 9/50\n",
            "\u001b[1m3180/3180\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0063 - mae: 0.0380\n",
            "Epoch 10/50\n",
            "\u001b[1m3180/3180\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0062 - mae: 0.0370\n",
            "Epoch 11/50\n",
            "\u001b[1m3180/3180\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0062 - mae: 0.0368\n",
            "Epoch 12/50\n",
            "\u001b[1m3180/3180\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 0.0062 - mae: 0.0365\n",
            "Epoch 13/50\n",
            "\u001b[1m3180/3180\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0065 - mae: 0.0420\n",
            "Epoch 14/50\n",
            "\u001b[1m3180/3180\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 0.0065 - mae: 0.0377\n",
            "Epoch 15/50\n",
            "\u001b[1m3180/3180\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 0.0061 - mae: 0.0364\n",
            "Epoch 16/50\n",
            "\u001b[1m3180/3180\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 0.0062 - mae: 0.0363\n",
            "Epoch 17/50\n",
            "\u001b[1m3180/3180\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 0.0064 - mae: 0.0374\n",
            "Epoch 18/50\n",
            "\u001b[1m3180/3180\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0062 - mae: 0.0360\n",
            "Epoch 19/50\n",
            "\u001b[1m3180/3180\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 0.0060 - mae: 0.0353\n",
            "Epoch 20/50\n",
            "\u001b[1m3180/3180\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0061 - mae: 0.0353\n",
            "Epoch 21/50\n",
            "\u001b[1m3180/3180\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0064 - mae: 0.0367\n",
            "Epoch 22/50\n",
            "\u001b[1m3180/3180\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0065 - mae: 0.0395\n",
            "Epoch 23/50\n",
            "\u001b[1m3180/3180\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 0.0063 - mae: 0.0377\n",
            "Epoch 24/50\n",
            "\u001b[1m3180/3180\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0062 - mae: 0.0375\n",
            "Epoch 25/50\n",
            "\u001b[1m3180/3180\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 0.0062 - mae: 0.0368\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Model must be fitted before making predictions",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m()\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m task3_results = \u001b[43mlab\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_task3\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwindow_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwindow_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_configs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeep_learning_models\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müéâ Deep Learning models training completed!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müìä Training Results Summary:\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/Project/Time-Series-Forecasting/time_series_forecasting/analysis/lab_interface/lab4_interface.py:201\u001b[39m, in \u001b[36mLab4Interface.execute_task3\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute_task3\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs) -> Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m    200\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Execute Task 3: Deep learning models.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtask_executor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_task3\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprocessed_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/Project/Time-Series-Forecasting/time_series_forecasting/analysis/lab_interface/task_executor.py:87\u001b[39m, in \u001b[36mTaskExecutor.execute_task3\u001b[39m\u001b[34m(self, data, **kwargs)\u001b[39m\n\u001b[32m     85\u001b[39m \u001b[38;5;66;03m# Remove model_configs from kwargs to avoid duplicate argument error\u001b[39;00m\n\u001b[32m     86\u001b[39m clean_kwargs = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k != \u001b[33m'\u001b[39m\u001b[33mmodel_configs\u001b[39m\u001b[33m'\u001b[39m}\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_model_task\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtask3\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_configs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mclean_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/Project/Time-Series-Forecasting/time_series_forecasting/analysis/lab_interface/task_executor.py:162\u001b[39m, in \u001b[36mTaskExecutor._execute_model_task\u001b[39m\u001b[34m(self, task_name, data, model_configs, **kwargs)\u001b[39m\n\u001b[32m    155\u001b[39m train_history = model.fit(\n\u001b[32m    156\u001b[39m     train_data=train_data,\n\u001b[32m    157\u001b[39m     validation_data=val_data,\n\u001b[32m    158\u001b[39m     **model_config.get(\u001b[33m'\u001b[39m\u001b[33mtrain_params\u001b[39m\u001b[33m'\u001b[39m, {})\n\u001b[32m    159\u001b[39m )\n\u001b[32m    161\u001b[39m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m predictions[model_name] = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpredict_params\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[38;5;66;03m# Evaluate model\u001b[39;00m\n\u001b[32m    168\u001b[39m metrics[model_name] = model.evaluate(\n\u001b[32m    169\u001b[39m     data=test_data,\n\u001b[32m    170\u001b[39m     metrics=model_config.get(\u001b[33m'\u001b[39m\u001b[33mmetrics\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m    171\u001b[39m     **model_config.get(\u001b[33m'\u001b[39m\u001b[33mevaluate_params\u001b[39m\u001b[33m'\u001b[39m, {})\n\u001b[32m    172\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/Project/Time-Series-Forecasting/time_series_forecasting/models/deep_learning/rnn_models.py:93\u001b[39m, in \u001b[36mBaseRNNModel.predict\u001b[39m\u001b[34m(self, data, **kwargs)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     83\u001b[39m \u001b[33;03mMake predictions.\u001b[39;00m\n\u001b[32m     84\u001b[39m \u001b[33;03m\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     90\u001b[39m \u001b[33;03m    Model predictions\u001b[39;00m\n\u001b[32m     91\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_fitted:\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mModel must be fitted before making predictions\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model.predict(data, **kwargs)\n",
            "\u001b[31mValueError\u001b[39m: Model must be fitted before making predictions"
          ]
        }
      ],
      "source": [
        "# Execute Task 3 - Train deep learning models\n",
        "print(\"üöÄ Training Deep Learning Models...\")\n",
        "print(\"=\" * 60)\n",
        "print(\"‚è∞ This may take several minutes depending on your hardware...\")\n",
        "print(\"üí° Models will use early stopping to prevent overfitting\")\n",
        "print()\n",
        "\n",
        "# Start training\n",
        "task3_results = lab.execute_task3(\n",
        "    window_config=window_config,\n",
        "    model_configs=deep_learning_models\n",
        ")\n",
        "\n",
        "print(\"\\nüéâ Deep Learning models training completed!\")\n",
        "print(\"\\nüìä Training Results Summary:\")\n",
        "print(\"=\" * 45)\n",
        "\n",
        "dl_model_summary = {}\n",
        "for model_name, model_info in task3_results.get('models', {}).items():\n",
        "    metrics = model_info['metrics']\n",
        "    model_type = model_info['type']\n",
        "    \n",
        "    print(f\"\\nüß† {model_name} ({model_type}):\")\n",
        "    mae = metrics.get('mae', 'N/A')\n",
        "    rmse = metrics.get('rmse', 'N/A')\n",
        "    \n",
        "    print(f\"  üìà MAE:  {mae:.4f}\" if isinstance(mae, (int, float)) else f\"  üìà MAE:  {mae}\")\n",
        "    print(f\"  üìà RMSE: {rmse:.4f}\" if isinstance(rmse, (int, float)) else f\"  üìà RMSE: {rmse}\")\n",
        "    \n",
        "    # Analyze model characteristics\n",
        "    if 'RNN' in model_name:\n",
        "        print(\"  üîç Architecture: Simple RNN - Basic recurrent processing\")\n",
        "        print(\"  ‚ö° Speed: Fast training, may struggle with long sequences\")\n",
        "        \n",
        "    elif 'GRU' in model_name:\n",
        "        print(\"  üîç Architecture: GRU - Gated recurrent with reset/update gates\")\n",
        "        print(\"  ‚ö° Balance: Good performance vs computational efficiency\")\n",
        "        \n",
        "    elif 'LSTM' in model_name:\n",
        "        print(\"  üîç Architecture: LSTM - Long Short-Term Memory with forget gates\")\n",
        "        print(\"  ‚ö° Memory: Best for long-term dependencies\")\n",
        "    \n",
        "    # Store for comparison\n",
        "    dl_model_summary[model_name] = {\n",
        "        'type': model_type,\n",
        "        'mae': mae,\n",
        "        'rmse': rmse,\n",
        "        'architecture': model_name\n",
        "    }\n",
        "\n",
        "print(f\"\\n‚úÖ Successfully trained {len(deep_learning_models)} deep learning models\")\n",
        "print(\"üíæ Results stored for visualization and analysis\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3.3 Task 3 Summary\n",
        "\n",
        "‚úÖ **Task 3 ho√†n th√†nh th√†nh c√¥ng! (4 ƒëi·ªÉm)**\n",
        "\n",
        "### Deep Learning Models Trained:\n",
        "1. **Simple RNN** - Basic recurrent neural network\n",
        "2. **GRU** - Gated Recurrent Unit v·ªõi gate mechanisms\n",
        "3. **LSTM** - Long Short-Term Memory cho long-term dependencies\n",
        "\n",
        "### Key Features:\n",
        "- ‚úÖ Early stopping ƒë·ªÉ prevent overfitting\n",
        "- ‚úÖ Comprehensive evaluation v·ªõi MAE/RMSE\n",
        "- ‚úÖ Architecture comparison analysis\n",
        "- ‚úÖ Performance benchmarking\n",
        "\n",
        "**‚û°Ô∏è S·∫µn s√†ng chuy·ªÉn sang Task 4: Transformer Models**\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
